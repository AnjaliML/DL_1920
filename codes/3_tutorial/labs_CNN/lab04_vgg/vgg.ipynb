{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM2M1Tn73NQ5",
        "colab_type": "text"
      },
      "source": [
        "# VGG on CIFAR\n",
        "In this lab we will train a VGG model on the CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeBGrEwi06fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vufhok43UWG",
        "colab_type": "text"
      },
      "source": [
        "It is recommended to use the GPU for this exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTnvxLin1LNV",
        "colab_type": "code",
        "outputId": "cf91e1bc-4eb2-48d7-9438-12e0bf61ea4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "use_cuda = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYGgIG8SGIr9",
        "colab_type": "text"
      },
      "source": [
        "### Load the CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40KsWyBt2qmv",
        "colab_type": "code",
        "outputId": "7d3247f1-42b4-4b27-bc4a-1314c6d7c442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "batch_size = # COMPLETE HERE\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLHJlUyjGNhA",
        "colab_type": "text"
      },
      "source": [
        "### Define the VGG architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkHt81xb2-SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG_convnet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(VGG_convnet, self).__init__()\n",
        "\n",
        "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16        \n",
        "        self.conv1a = nn.Conv2d(3,   64,  kernel_size=3, padding=1 )\n",
        "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
        "        self.pool1  = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
        "        self.conv2a = # COMPLETE HERE\n",
        "        self.conv2b = # COMPLETE HERE\n",
        "        self.pool2  = # COMPLETE HERE\n",
        "\n",
        "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4        \n",
        "        self.conv3a = # COMPLETE HERE\n",
        "        self.conv3b = # COMPLETE HERE\n",
        "        self.pool3  = # COMPLETE HERE\n",
        "        \n",
        "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
        "        self.conv4a = # COMPLETE HERE\n",
        "        self.pool4  = # COMPLETE HERE\n",
        "\n",
        "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
        "        self.linear1 = nn.Linear(2048, 4096)\n",
        "        self.linear2 = # COMPLETE HERE\n",
        "        self.linear3 = # COMPLETE HERE\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16\n",
        "        x = self.conv1a(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv1b(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "\n",
        "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "\n",
        "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "\n",
        "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
        "        x = x.view(# COMPLETE HERE)\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "        x = # COMPLETE HERE\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4iagyWQ6Axl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the network and move its parameters to either GPU or CPU\n",
        "net = VGG_convnet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvENiJAt6Auj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "my_lr=0.25\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etpYx0fIHNvc",
        "colab_type": "text"
      },
      "source": [
        "### Train the model on the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmSJpneX6ApZ",
        "colab_type": "code",
        "outputId": "d42e1825-3e72-46f0-fe6f-b106bfac8d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start=time.time()\n",
        "\n",
        "optimizer=torch.optim.SGD(net.parameters(), lr=my_lr)\n",
        "\n",
        "for epoch in range(1,30):\n",
        "\n",
        "  for i, (x_batch, y_batch) in enumerate(trainloader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
        "    \n",
        "    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n",
        "\n",
        "    y_pred = net(x_batch)\n",
        "\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute relevant metrics\n",
        "    \n",
        "    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n",
        "\n",
        "    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n",
        "\n",
        "    elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
        "\n",
        "    # Show progress every 20 batches \n",
        "    if not i % 20:\n",
        "      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, time: 0.097s, loss: 2.304, train accuracy: 0.094\n",
            "epoch: 1, time: 1.497s, loss: 2.304, train accuracy: 0.102\n",
            "epoch: 1, time: 2.857s, loss: 2.303, train accuracy: 0.109\n",
            "epoch: 1, time: 4.221s, loss: 2.304, train accuracy: 0.109\n",
            "epoch: 1, time: 5.584s, loss: 2.303, train accuracy: 0.125\n",
            "epoch: 1, time: 6.953s, loss: 2.306, train accuracy: 0.094\n",
            "epoch: 1, time: 8.316s, loss: 2.300, train accuracy: 0.102\n",
            "epoch: 1, time: 9.678s, loss: 2.299, train accuracy: 0.109\n",
            "epoch: 1, time: 11.064s, loss: 2.307, train accuracy: 0.039\n",
            "epoch: 1, time: 12.446s, loss: 2.300, train accuracy: 0.094\n",
            "epoch: 1, time: 13.833s, loss: 2.296, train accuracy: 0.125\n",
            "epoch: 1, time: 15.217s, loss: 2.301, train accuracy: 0.062\n",
            "epoch: 1, time: 16.605s, loss: 2.235, train accuracy: 0.148\n",
            "epoch: 1, time: 17.985s, loss: 2.315, train accuracy: 0.047\n",
            "epoch: 1, time: 19.366s, loss: 2.297, train accuracy: 0.086\n",
            "epoch: 1, time: 20.764s, loss: 2.303, train accuracy: 0.125\n",
            "epoch: 1, time: 22.144s, loss: 2.304, train accuracy: 0.133\n",
            "epoch: 1, time: 23.521s, loss: 2.292, train accuracy: 0.117\n",
            "epoch: 1, time: 24.901s, loss: 2.224, train accuracy: 0.211\n",
            "epoch: 1, time: 26.286s, loss: 2.190, train accuracy: 0.273\n",
            "epoch: 2, time: 27.031s, loss: 2.193, train accuracy: 0.172\n",
            "epoch: 2, time: 28.416s, loss: 2.333, train accuracy: 0.078\n",
            "epoch: 2, time: 29.805s, loss: 2.308, train accuracy: 0.094\n",
            "epoch: 2, time: 31.189s, loss: 2.306, train accuracy: 0.094\n",
            "epoch: 2, time: 32.562s, loss: 2.299, train accuracy: 0.125\n",
            "epoch: 2, time: 33.928s, loss: 2.305, train accuracy: 0.070\n",
            "epoch: 2, time: 35.298s, loss: 2.305, train accuracy: 0.102\n",
            "epoch: 2, time: 36.664s, loss: 2.299, train accuracy: 0.109\n",
            "epoch: 2, time: 38.030s, loss: 2.302, train accuracy: 0.078\n",
            "epoch: 2, time: 39.399s, loss: 2.304, train accuracy: 0.109\n",
            "epoch: 2, time: 40.770s, loss: 2.306, train accuracy: 0.102\n",
            "epoch: 2, time: 42.145s, loss: 2.302, train accuracy: 0.086\n",
            "epoch: 2, time: 43.521s, loss: 2.307, train accuracy: 0.070\n",
            "epoch: 2, time: 44.887s, loss: 2.303, train accuracy: 0.109\n",
            "epoch: 2, time: 46.252s, loss: 2.297, train accuracy: 0.070\n",
            "epoch: 2, time: 47.612s, loss: 2.301, train accuracy: 0.078\n",
            "epoch: 2, time: 48.980s, loss: 2.293, train accuracy: 0.180\n",
            "epoch: 2, time: 50.344s, loss: 2.296, train accuracy: 0.148\n",
            "epoch: 2, time: 51.704s, loss: 2.300, train accuracy: 0.094\n",
            "epoch: 2, time: 53.063s, loss: 2.309, train accuracy: 0.086\n",
            "epoch: 3, time: 53.791s, loss: 2.303, train accuracy: 0.086\n",
            "epoch: 3, time: 55.158s, loss: 2.315, train accuracy: 0.086\n",
            "epoch: 3, time: 56.521s, loss: 2.305, train accuracy: 0.086\n",
            "epoch: 3, time: 57.876s, loss: 2.303, train accuracy: 0.125\n",
            "epoch: 3, time: 59.233s, loss: 2.308, train accuracy: 0.086\n",
            "epoch: 3, time: 60.589s, loss: 2.303, train accuracy: 0.117\n",
            "epoch: 3, time: 61.961s, loss: 2.300, train accuracy: 0.125\n",
            "epoch: 3, time: 63.312s, loss: 2.309, train accuracy: 0.094\n",
            "epoch: 3, time: 64.683s, loss: 2.303, train accuracy: 0.094\n",
            "epoch: 3, time: 66.038s, loss: 2.301, train accuracy: 0.148\n",
            "epoch: 3, time: 67.401s, loss: 2.303, train accuracy: 0.094\n",
            "epoch: 3, time: 68.746s, loss: 2.303, train accuracy: 0.086\n",
            "epoch: 3, time: 70.096s, loss: 2.310, train accuracy: 0.125\n",
            "epoch: 3, time: 71.447s, loss: 2.302, train accuracy: 0.141\n",
            "epoch: 3, time: 72.807s, loss: 2.304, train accuracy: 0.062\n",
            "epoch: 3, time: 74.170s, loss: 2.303, train accuracy: 0.070\n",
            "epoch: 3, time: 75.536s, loss: 2.240, train accuracy: 0.117\n",
            "epoch: 3, time: 76.892s, loss: 2.206, train accuracy: 0.164\n",
            "epoch: 3, time: 78.259s, loss: 2.179, train accuracy: 0.172\n",
            "epoch: 3, time: 79.615s, loss: 2.264, train accuracy: 0.156\n",
            "epoch: 4, time: 80.354s, loss: 2.199, train accuracy: 0.156\n",
            "epoch: 4, time: 81.723s, loss: 1.999, train accuracy: 0.227\n",
            "epoch: 4, time: 83.092s, loss: 2.056, train accuracy: 0.156\n",
            "epoch: 4, time: 84.459s, loss: 2.023, train accuracy: 0.250\n",
            "epoch: 4, time: 85.838s, loss: 2.130, train accuracy: 0.117\n",
            "epoch: 4, time: 87.205s, loss: 1.995, train accuracy: 0.195\n",
            "epoch: 4, time: 88.567s, loss: 2.081, train accuracy: 0.281\n",
            "epoch: 4, time: 89.936s, loss: 1.958, train accuracy: 0.180\n",
            "epoch: 4, time: 91.306s, loss: 2.378, train accuracy: 0.062\n",
            "epoch: 4, time: 92.667s, loss: 1.979, train accuracy: 0.188\n",
            "epoch: 4, time: 94.033s, loss: 1.958, train accuracy: 0.219\n",
            "epoch: 4, time: 95.402s, loss: 2.029, train accuracy: 0.188\n",
            "epoch: 4, time: 96.781s, loss: 1.974, train accuracy: 0.211\n",
            "epoch: 4, time: 98.154s, loss: 1.924, train accuracy: 0.258\n",
            "epoch: 4, time: 99.515s, loss: 1.903, train accuracy: 0.328\n",
            "epoch: 4, time: 100.879s, loss: 1.848, train accuracy: 0.266\n",
            "epoch: 4, time: 102.252s, loss: 2.057, train accuracy: 0.219\n",
            "epoch: 4, time: 103.619s, loss: 1.884, train accuracy: 0.258\n",
            "epoch: 4, time: 104.986s, loss: 1.947, train accuracy: 0.281\n",
            "epoch: 4, time: 106.370s, loss: 1.850, train accuracy: 0.320\n",
            "epoch: 5, time: 107.107s, loss: 1.899, train accuracy: 0.250\n",
            "epoch: 5, time: 108.469s, loss: 1.876, train accuracy: 0.289\n",
            "epoch: 5, time: 109.838s, loss: 1.778, train accuracy: 0.281\n",
            "epoch: 5, time: 111.225s, loss: 1.762, train accuracy: 0.312\n",
            "epoch: 5, time: 112.596s, loss: 1.683, train accuracy: 0.352\n",
            "epoch: 5, time: 113.966s, loss: 1.815, train accuracy: 0.242\n",
            "epoch: 5, time: 115.332s, loss: 1.815, train accuracy: 0.344\n",
            "epoch: 5, time: 116.703s, loss: 1.624, train accuracy: 0.352\n",
            "epoch: 5, time: 118.071s, loss: 1.750, train accuracy: 0.336\n",
            "epoch: 5, time: 119.441s, loss: 1.715, train accuracy: 0.352\n",
            "epoch: 5, time: 120.812s, loss: 1.764, train accuracy: 0.391\n",
            "epoch: 5, time: 122.196s, loss: 1.702, train accuracy: 0.328\n",
            "epoch: 5, time: 123.568s, loss: 1.621, train accuracy: 0.367\n",
            "epoch: 5, time: 124.939s, loss: 1.695, train accuracy: 0.352\n",
            "epoch: 5, time: 126.304s, loss: 1.559, train accuracy: 0.336\n",
            "epoch: 5, time: 127.680s, loss: 1.622, train accuracy: 0.391\n",
            "epoch: 5, time: 129.050s, loss: 1.610, train accuracy: 0.344\n",
            "epoch: 5, time: 130.423s, loss: 1.631, train accuracy: 0.414\n",
            "epoch: 5, time: 131.798s, loss: 1.746, train accuracy: 0.344\n",
            "epoch: 5, time: 133.169s, loss: 1.626, train accuracy: 0.383\n",
            "epoch: 6, time: 133.914s, loss: 1.753, train accuracy: 0.359\n",
            "epoch: 6, time: 135.280s, loss: 1.604, train accuracy: 0.367\n",
            "epoch: 6, time: 136.655s, loss: 1.514, train accuracy: 0.477\n",
            "epoch: 6, time: 138.032s, loss: 1.628, train accuracy: 0.375\n",
            "epoch: 6, time: 139.398s, loss: 1.700, train accuracy: 0.391\n",
            "epoch: 6, time: 140.767s, loss: 1.629, train accuracy: 0.375\n",
            "epoch: 6, time: 142.131s, loss: 1.438, train accuracy: 0.469\n",
            "epoch: 6, time: 143.497s, loss: 1.562, train accuracy: 0.453\n",
            "epoch: 6, time: 144.862s, loss: 1.446, train accuracy: 0.492\n",
            "epoch: 6, time: 146.221s, loss: 1.433, train accuracy: 0.469\n",
            "epoch: 6, time: 147.587s, loss: 1.429, train accuracy: 0.461\n",
            "epoch: 6, time: 148.962s, loss: 1.562, train accuracy: 0.391\n",
            "epoch: 6, time: 150.332s, loss: 1.325, train accuracy: 0.531\n",
            "epoch: 6, time: 151.718s, loss: 1.292, train accuracy: 0.539\n",
            "epoch: 6, time: 153.091s, loss: 1.757, train accuracy: 0.383\n",
            "epoch: 6, time: 154.460s, loss: 1.239, train accuracy: 0.531\n",
            "epoch: 6, time: 155.822s, loss: 1.359, train accuracy: 0.516\n",
            "epoch: 6, time: 157.185s, loss: 1.289, train accuracy: 0.586\n",
            "epoch: 6, time: 158.565s, loss: 1.374, train accuracy: 0.477\n",
            "epoch: 6, time: 159.920s, loss: 1.380, train accuracy: 0.469\n",
            "epoch: 7, time: 160.645s, loss: 1.130, train accuracy: 0.594\n",
            "epoch: 7, time: 162.014s, loss: 1.220, train accuracy: 0.555\n",
            "epoch: 7, time: 163.375s, loss: 1.248, train accuracy: 0.539\n",
            "epoch: 7, time: 164.748s, loss: 1.396, train accuracy: 0.500\n",
            "epoch: 7, time: 166.109s, loss: 1.327, train accuracy: 0.531\n",
            "epoch: 7, time: 167.465s, loss: 1.241, train accuracy: 0.586\n",
            "epoch: 7, time: 168.827s, loss: 1.382, train accuracy: 0.508\n",
            "epoch: 7, time: 170.195s, loss: 1.250, train accuracy: 0.523\n",
            "epoch: 7, time: 171.566s, loss: 1.082, train accuracy: 0.656\n",
            "epoch: 7, time: 172.927s, loss: 1.229, train accuracy: 0.586\n",
            "epoch: 7, time: 174.294s, loss: 1.258, train accuracy: 0.562\n",
            "epoch: 7, time: 175.661s, loss: 1.147, train accuracy: 0.617\n",
            "epoch: 7, time: 177.026s, loss: 1.341, train accuracy: 0.531\n",
            "epoch: 7, time: 178.388s, loss: 1.187, train accuracy: 0.594\n",
            "epoch: 7, time: 179.758s, loss: 1.239, train accuracy: 0.539\n",
            "epoch: 7, time: 181.129s, loss: 1.160, train accuracy: 0.594\n",
            "epoch: 7, time: 182.508s, loss: 1.225, train accuracy: 0.578\n",
            "epoch: 7, time: 183.870s, loss: 1.323, train accuracy: 0.562\n",
            "epoch: 7, time: 185.237s, loss: 1.098, train accuracy: 0.602\n",
            "epoch: 7, time: 186.608s, loss: 1.227, train accuracy: 0.586\n",
            "epoch: 8, time: 187.341s, loss: 1.026, train accuracy: 0.688\n",
            "epoch: 8, time: 188.714s, loss: 1.304, train accuracy: 0.523\n",
            "epoch: 8, time: 190.095s, loss: 1.418, train accuracy: 0.461\n",
            "epoch: 8, time: 191.468s, loss: 1.047, train accuracy: 0.625\n",
            "epoch: 8, time: 192.850s, loss: 0.949, train accuracy: 0.648\n",
            "epoch: 8, time: 194.235s, loss: 1.080, train accuracy: 0.625\n",
            "epoch: 8, time: 195.601s, loss: 1.056, train accuracy: 0.609\n",
            "epoch: 8, time: 196.965s, loss: 1.340, train accuracy: 0.547\n",
            "epoch: 8, time: 198.337s, loss: 1.175, train accuracy: 0.602\n",
            "epoch: 8, time: 199.700s, loss: 1.094, train accuracy: 0.617\n",
            "epoch: 8, time: 201.076s, loss: 1.051, train accuracy: 0.609\n",
            "epoch: 8, time: 202.429s, loss: 0.955, train accuracy: 0.695\n",
            "epoch: 8, time: 203.791s, loss: 0.958, train accuracy: 0.672\n",
            "epoch: 8, time: 205.150s, loss: 1.156, train accuracy: 0.609\n",
            "epoch: 8, time: 206.516s, loss: 1.687, train accuracy: 0.484\n",
            "epoch: 8, time: 207.876s, loss: 0.787, train accuracy: 0.719\n",
            "epoch: 8, time: 209.236s, loss: 0.910, train accuracy: 0.680\n",
            "epoch: 8, time: 210.599s, loss: 0.900, train accuracy: 0.695\n",
            "epoch: 8, time: 211.981s, loss: 1.056, train accuracy: 0.609\n",
            "epoch: 8, time: 213.342s, loss: 0.958, train accuracy: 0.656\n",
            "epoch: 9, time: 214.071s, loss: 0.758, train accuracy: 0.758\n",
            "epoch: 9, time: 215.427s, loss: 1.029, train accuracy: 0.664\n",
            "epoch: 9, time: 216.789s, loss: 0.816, train accuracy: 0.695\n",
            "epoch: 9, time: 218.151s, loss: 0.900, train accuracy: 0.672\n",
            "epoch: 9, time: 219.503s, loss: 0.783, train accuracy: 0.727\n",
            "epoch: 9, time: 220.857s, loss: 0.895, train accuracy: 0.703\n",
            "epoch: 9, time: 222.228s, loss: 0.758, train accuracy: 0.734\n",
            "epoch: 9, time: 223.582s, loss: 1.008, train accuracy: 0.641\n",
            "epoch: 9, time: 224.931s, loss: 0.824, train accuracy: 0.719\n",
            "epoch: 9, time: 226.292s, loss: 0.834, train accuracy: 0.680\n",
            "epoch: 9, time: 227.646s, loss: 0.731, train accuracy: 0.781\n",
            "epoch: 9, time: 228.997s, loss: 0.798, train accuracy: 0.719\n",
            "epoch: 9, time: 230.341s, loss: 0.917, train accuracy: 0.680\n",
            "epoch: 9, time: 231.694s, loss: 0.806, train accuracy: 0.727\n",
            "epoch: 9, time: 233.044s, loss: 0.771, train accuracy: 0.656\n",
            "epoch: 9, time: 234.390s, loss: 0.760, train accuracy: 0.727\n",
            "epoch: 9, time: 235.742s, loss: 0.663, train accuracy: 0.805\n",
            "epoch: 9, time: 237.088s, loss: 0.911, train accuracy: 0.672\n",
            "epoch: 9, time: 238.428s, loss: 0.716, train accuracy: 0.758\n",
            "epoch: 9, time: 239.779s, loss: 0.795, train accuracy: 0.703\n",
            "epoch: 10, time: 240.498s, loss: 0.783, train accuracy: 0.727\n",
            "epoch: 10, time: 241.851s, loss: 0.668, train accuracy: 0.727\n",
            "epoch: 10, time: 243.206s, loss: 0.726, train accuracy: 0.766\n",
            "epoch: 10, time: 244.549s, loss: 0.517, train accuracy: 0.828\n",
            "epoch: 10, time: 245.905s, loss: 0.672, train accuracy: 0.789\n",
            "epoch: 10, time: 247.257s, loss: 1.087, train accuracy: 0.570\n",
            "epoch: 10, time: 248.608s, loss: 0.593, train accuracy: 0.781\n",
            "epoch: 10, time: 249.956s, loss: 0.513, train accuracy: 0.828\n",
            "epoch: 10, time: 251.302s, loss: 0.605, train accuracy: 0.797\n",
            "epoch: 10, time: 252.643s, loss: 0.924, train accuracy: 0.734\n",
            "epoch: 10, time: 254.005s, loss: 1.017, train accuracy: 0.672\n",
            "epoch: 10, time: 255.348s, loss: 0.797, train accuracy: 0.703\n",
            "epoch: 10, time: 256.692s, loss: 0.822, train accuracy: 0.672\n",
            "epoch: 10, time: 258.039s, loss: 0.756, train accuracy: 0.719\n",
            "epoch: 10, time: 259.389s, loss: 0.984, train accuracy: 0.695\n",
            "epoch: 10, time: 260.750s, loss: 0.765, train accuracy: 0.773\n",
            "epoch: 10, time: 262.113s, loss: 0.770, train accuracy: 0.750\n",
            "epoch: 10, time: 263.471s, loss: 0.732, train accuracy: 0.742\n",
            "epoch: 10, time: 264.831s, loss: 0.576, train accuracy: 0.828\n",
            "epoch: 10, time: 266.191s, loss: 0.797, train accuracy: 0.750\n",
            "epoch: 11, time: 266.917s, loss: 0.550, train accuracy: 0.828\n",
            "epoch: 11, time: 268.271s, loss: 0.446, train accuracy: 0.812\n",
            "epoch: 11, time: 269.621s, loss: 0.636, train accuracy: 0.742\n",
            "epoch: 11, time: 270.972s, loss: 0.595, train accuracy: 0.812\n",
            "epoch: 11, time: 272.338s, loss: 0.430, train accuracy: 0.828\n",
            "epoch: 11, time: 273.701s, loss: 0.866, train accuracy: 0.680\n",
            "epoch: 11, time: 275.074s, loss: 0.489, train accuracy: 0.797\n",
            "epoch: 11, time: 276.438s, loss: 0.627, train accuracy: 0.758\n",
            "epoch: 11, time: 277.793s, loss: 0.505, train accuracy: 0.836\n",
            "epoch: 11, time: 279.154s, loss: 0.655, train accuracy: 0.812\n",
            "epoch: 11, time: 280.510s, loss: 0.722, train accuracy: 0.672\n",
            "epoch: 11, time: 281.878s, loss: 0.611, train accuracy: 0.781\n",
            "epoch: 11, time: 283.236s, loss: 0.619, train accuracy: 0.781\n",
            "epoch: 11, time: 284.606s, loss: 0.597, train accuracy: 0.812\n",
            "epoch: 11, time: 285.984s, loss: 0.693, train accuracy: 0.781\n",
            "epoch: 11, time: 287.339s, loss: 0.559, train accuracy: 0.812\n",
            "epoch: 11, time: 288.704s, loss: 0.582, train accuracy: 0.773\n",
            "epoch: 11, time: 290.060s, loss: 0.496, train accuracy: 0.836\n",
            "epoch: 11, time: 291.425s, loss: 0.552, train accuracy: 0.820\n",
            "epoch: 11, time: 292.771s, loss: 0.520, train accuracy: 0.820\n",
            "epoch: 12, time: 293.496s, loss: 0.434, train accuracy: 0.859\n",
            "epoch: 12, time: 294.849s, loss: 0.352, train accuracy: 0.883\n",
            "epoch: 12, time: 296.213s, loss: 0.275, train accuracy: 0.906\n",
            "epoch: 12, time: 297.560s, loss: 0.461, train accuracy: 0.844\n",
            "epoch: 12, time: 298.915s, loss: 0.289, train accuracy: 0.891\n",
            "epoch: 12, time: 300.261s, loss: 0.294, train accuracy: 0.914\n",
            "epoch: 12, time: 301.614s, loss: 0.568, train accuracy: 0.805\n",
            "epoch: 12, time: 302.961s, loss: 0.382, train accuracy: 0.906\n",
            "epoch: 12, time: 304.314s, loss: 0.280, train accuracy: 0.898\n",
            "epoch: 12, time: 305.675s, loss: 0.427, train accuracy: 0.852\n",
            "epoch: 12, time: 307.038s, loss: 0.628, train accuracy: 0.828\n",
            "epoch: 12, time: 308.393s, loss: 0.303, train accuracy: 0.906\n",
            "epoch: 12, time: 309.755s, loss: 0.454, train accuracy: 0.828\n",
            "epoch: 12, time: 311.114s, loss: 0.315, train accuracy: 0.859\n",
            "epoch: 12, time: 312.472s, loss: 0.264, train accuracy: 0.906\n",
            "epoch: 12, time: 313.826s, loss: 0.486, train accuracy: 0.828\n",
            "epoch: 12, time: 315.177s, loss: 0.446, train accuracy: 0.828\n",
            "epoch: 12, time: 316.526s, loss: 0.350, train accuracy: 0.875\n",
            "epoch: 12, time: 317.879s, loss: 0.529, train accuracy: 0.828\n",
            "epoch: 12, time: 319.220s, loss: 0.459, train accuracy: 0.844\n",
            "epoch: 13, time: 319.940s, loss: 0.276, train accuracy: 0.930\n",
            "epoch: 13, time: 321.301s, loss: 0.274, train accuracy: 0.914\n",
            "epoch: 13, time: 322.665s, loss: 0.336, train accuracy: 0.859\n",
            "epoch: 13, time: 324.023s, loss: 0.332, train accuracy: 0.883\n",
            "epoch: 13, time: 325.374s, loss: 0.364, train accuracy: 0.875\n",
            "epoch: 13, time: 326.728s, loss: 0.317, train accuracy: 0.875\n",
            "epoch: 13, time: 328.096s, loss: 0.340, train accuracy: 0.883\n",
            "epoch: 13, time: 329.452s, loss: 0.235, train accuracy: 0.930\n",
            "epoch: 13, time: 330.803s, loss: 0.352, train accuracy: 0.883\n",
            "epoch: 13, time: 332.165s, loss: 0.442, train accuracy: 0.852\n",
            "epoch: 13, time: 333.512s, loss: 0.460, train accuracy: 0.828\n",
            "epoch: 13, time: 334.866s, loss: 0.252, train accuracy: 0.891\n",
            "epoch: 13, time: 336.216s, loss: 0.486, train accuracy: 0.867\n",
            "epoch: 13, time: 337.573s, loss: 0.404, train accuracy: 0.898\n",
            "epoch: 13, time: 338.931s, loss: 0.291, train accuracy: 0.891\n",
            "epoch: 13, time: 340.283s, loss: 0.462, train accuracy: 0.836\n",
            "epoch: 13, time: 341.634s, loss: 0.372, train accuracy: 0.859\n",
            "epoch: 13, time: 342.986s, loss: 0.449, train accuracy: 0.836\n",
            "epoch: 13, time: 344.335s, loss: 0.363, train accuracy: 0.859\n",
            "epoch: 13, time: 345.690s, loss: 0.411, train accuracy: 0.797\n",
            "epoch: 14, time: 346.418s, loss: 0.189, train accuracy: 0.922\n",
            "epoch: 14, time: 347.766s, loss: 0.186, train accuracy: 0.953\n",
            "epoch: 14, time: 349.116s, loss: 0.262, train accuracy: 0.914\n",
            "epoch: 14, time: 350.465s, loss: 0.328, train accuracy: 0.852\n",
            "epoch: 14, time: 351.820s, loss: 0.203, train accuracy: 0.922\n",
            "epoch: 14, time: 353.169s, loss: 0.684, train accuracy: 0.781\n",
            "epoch: 14, time: 354.516s, loss: 0.241, train accuracy: 0.930\n",
            "epoch: 14, time: 355.870s, loss: 0.261, train accuracy: 0.938\n",
            "epoch: 14, time: 357.219s, loss: 0.303, train accuracy: 0.898\n",
            "epoch: 14, time: 358.561s, loss: 0.276, train accuracy: 0.891\n",
            "epoch: 14, time: 359.911s, loss: 0.237, train accuracy: 0.914\n",
            "epoch: 14, time: 361.257s, loss: 0.211, train accuracy: 0.922\n",
            "epoch: 14, time: 362.603s, loss: 0.223, train accuracy: 0.906\n",
            "epoch: 14, time: 363.951s, loss: 0.265, train accuracy: 0.914\n",
            "epoch: 14, time: 365.301s, loss: 0.283, train accuracy: 0.891\n",
            "epoch: 14, time: 366.667s, loss: 0.265, train accuracy: 0.930\n",
            "epoch: 14, time: 368.018s, loss: 0.232, train accuracy: 0.906\n",
            "epoch: 14, time: 369.370s, loss: 0.307, train accuracy: 0.898\n",
            "epoch: 14, time: 370.726s, loss: 0.315, train accuracy: 0.875\n",
            "epoch: 14, time: 372.075s, loss: 0.286, train accuracy: 0.891\n",
            "epoch: 15, time: 372.800s, loss: 0.354, train accuracy: 0.898\n",
            "epoch: 15, time: 374.164s, loss: 0.156, train accuracy: 0.945\n",
            "epoch: 15, time: 375.513s, loss: 0.087, train accuracy: 0.977\n",
            "epoch: 15, time: 376.862s, loss: 0.187, train accuracy: 0.930\n",
            "epoch: 15, time: 378.210s, loss: 0.159, train accuracy: 0.953\n",
            "epoch: 15, time: 379.559s, loss: 0.186, train accuracy: 0.930\n",
            "epoch: 15, time: 380.920s, loss: 0.129, train accuracy: 0.953\n",
            "epoch: 15, time: 382.276s, loss: 0.198, train accuracy: 0.938\n",
            "epoch: 15, time: 383.633s, loss: 0.270, train accuracy: 0.875\n",
            "epoch: 15, time: 384.974s, loss: 0.102, train accuracy: 0.969\n",
            "epoch: 15, time: 386.324s, loss: 0.230, train accuracy: 0.914\n",
            "epoch: 15, time: 387.670s, loss: 0.190, train accuracy: 0.922\n",
            "epoch: 15, time: 389.025s, loss: 0.298, train accuracy: 0.906\n",
            "epoch: 15, time: 390.377s, loss: 0.364, train accuracy: 0.898\n",
            "epoch: 15, time: 391.740s, loss: 0.229, train accuracy: 0.922\n",
            "epoch: 15, time: 393.104s, loss: 0.380, train accuracy: 0.875\n",
            "epoch: 15, time: 394.444s, loss: 0.137, train accuracy: 0.953\n",
            "epoch: 15, time: 395.790s, loss: 0.182, train accuracy: 0.930\n",
            "epoch: 15, time: 397.142s, loss: 0.259, train accuracy: 0.891\n",
            "epoch: 15, time: 398.497s, loss: 0.168, train accuracy: 0.914\n",
            "epoch: 16, time: 399.227s, loss: 0.135, train accuracy: 0.922\n",
            "epoch: 16, time: 400.565s, loss: 0.062, train accuracy: 0.977\n",
            "epoch: 16, time: 401.915s, loss: 0.167, train accuracy: 0.930\n",
            "epoch: 16, time: 403.280s, loss: 1.014, train accuracy: 0.867\n",
            "epoch: 16, time: 404.631s, loss: 0.236, train accuracy: 0.914\n",
            "epoch: 16, time: 405.978s, loss: 0.195, train accuracy: 0.945\n",
            "epoch: 16, time: 407.339s, loss: 0.097, train accuracy: 0.961\n",
            "epoch: 16, time: 408.687s, loss: 0.413, train accuracy: 0.859\n",
            "epoch: 16, time: 410.034s, loss: 0.139, train accuracy: 0.977\n",
            "epoch: 16, time: 411.384s, loss: 0.116, train accuracy: 0.953\n",
            "epoch: 16, time: 412.731s, loss: 0.223, train accuracy: 0.906\n",
            "epoch: 16, time: 414.086s, loss: 0.461, train accuracy: 0.883\n",
            "epoch: 16, time: 415.436s, loss: 0.068, train accuracy: 0.977\n",
            "epoch: 16, time: 416.791s, loss: 0.222, train accuracy: 0.930\n",
            "epoch: 16, time: 418.145s, loss: 0.132, train accuracy: 0.953\n",
            "epoch: 16, time: 419.492s, loss: 0.208, train accuracy: 0.930\n",
            "epoch: 16, time: 420.836s, loss: 0.175, train accuracy: 0.930\n",
            "epoch: 16, time: 422.195s, loss: 0.380, train accuracy: 0.859\n",
            "epoch: 16, time: 423.549s, loss: 0.186, train accuracy: 0.930\n",
            "epoch: 16, time: 424.912s, loss: 0.153, train accuracy: 0.938\n",
            "epoch: 17, time: 425.633s, loss: 0.078, train accuracy: 0.984\n",
            "epoch: 17, time: 426.979s, loss: 0.077, train accuracy: 0.961\n",
            "epoch: 17, time: 428.327s, loss: 0.036, train accuracy: 0.984\n",
            "epoch: 17, time: 429.691s, loss: 0.052, train accuracy: 0.977\n",
            "epoch: 17, time: 431.040s, loss: 0.086, train accuracy: 0.969\n",
            "epoch: 17, time: 432.390s, loss: 0.111, train accuracy: 0.953\n",
            "epoch: 17, time: 433.751s, loss: 0.089, train accuracy: 0.961\n",
            "epoch: 17, time: 435.096s, loss: 0.087, train accuracy: 0.977\n",
            "epoch: 17, time: 436.441s, loss: 0.260, train accuracy: 0.922\n",
            "epoch: 17, time: 437.797s, loss: 0.068, train accuracy: 0.984\n",
            "epoch: 17, time: 439.153s, loss: 0.221, train accuracy: 0.922\n",
            "epoch: 17, time: 440.504s, loss: 0.076, train accuracy: 0.977\n",
            "epoch: 17, time: 441.857s, loss: 0.109, train accuracy: 0.961\n",
            "epoch: 17, time: 443.217s, loss: 0.100, train accuracy: 0.969\n",
            "epoch: 17, time: 444.572s, loss: 0.182, train accuracy: 0.938\n",
            "epoch: 17, time: 445.924s, loss: 0.100, train accuracy: 0.969\n",
            "epoch: 17, time: 447.283s, loss: 0.109, train accuracy: 0.945\n",
            "epoch: 17, time: 448.642s, loss: 0.099, train accuracy: 0.953\n",
            "epoch: 17, time: 450.011s, loss: 0.095, train accuracy: 0.961\n",
            "epoch: 17, time: 451.372s, loss: 0.163, train accuracy: 0.969\n",
            "epoch: 18, time: 452.103s, loss: 0.075, train accuracy: 0.977\n",
            "epoch: 18, time: 453.452s, loss: 0.044, train accuracy: 0.984\n",
            "epoch: 18, time: 454.796s, loss: 0.097, train accuracy: 0.961\n",
            "epoch: 18, time: 456.145s, loss: 0.071, train accuracy: 0.977\n",
            "epoch: 18, time: 457.496s, loss: 0.053, train accuracy: 0.977\n",
            "epoch: 18, time: 458.852s, loss: 0.191, train accuracy: 0.953\n",
            "epoch: 18, time: 460.229s, loss: 0.046, train accuracy: 0.984\n",
            "epoch: 18, time: 461.592s, loss: 0.051, train accuracy: 0.984\n",
            "epoch: 18, time: 462.964s, loss: 0.139, train accuracy: 0.930\n",
            "epoch: 18, time: 464.317s, loss: 0.119, train accuracy: 0.961\n",
            "epoch: 18, time: 465.682s, loss: 0.088, train accuracy: 0.977\n",
            "epoch: 18, time: 467.041s, loss: 0.079, train accuracy: 0.977\n",
            "epoch: 18, time: 468.383s, loss: 0.042, train accuracy: 0.977\n",
            "epoch: 18, time: 469.721s, loss: 0.025, train accuracy: 0.992\n",
            "epoch: 18, time: 471.082s, loss: 0.139, train accuracy: 0.953\n",
            "epoch: 18, time: 472.426s, loss: 0.028, train accuracy: 0.992\n",
            "epoch: 18, time: 473.768s, loss: 0.167, train accuracy: 0.961\n",
            "epoch: 18, time: 475.109s, loss: 0.092, train accuracy: 0.969\n",
            "epoch: 18, time: 476.456s, loss: 0.379, train accuracy: 0.883\n",
            "epoch: 18, time: 477.814s, loss: 0.077, train accuracy: 0.969\n",
            "epoch: 19, time: 478.534s, loss: 0.097, train accuracy: 0.961\n",
            "epoch: 19, time: 479.871s, loss: 0.088, train accuracy: 0.969\n",
            "epoch: 19, time: 481.219s, loss: 0.027, train accuracy: 0.992\n",
            "epoch: 19, time: 482.570s, loss: 0.051, train accuracy: 0.977\n",
            "epoch: 19, time: 483.919s, loss: 0.129, train accuracy: 0.953\n",
            "epoch: 19, time: 485.258s, loss: 0.159, train accuracy: 0.969\n",
            "epoch: 19, time: 486.601s, loss: 0.043, train accuracy: 0.977\n",
            "epoch: 19, time: 487.969s, loss: 0.048, train accuracy: 0.992\n",
            "epoch: 19, time: 489.316s, loss: 0.097, train accuracy: 0.961\n",
            "epoch: 19, time: 490.660s, loss: 0.080, train accuracy: 0.977\n",
            "epoch: 19, time: 492.010s, loss: 0.038, train accuracy: 0.992\n",
            "epoch: 19, time: 493.356s, loss: 0.202, train accuracy: 0.945\n",
            "epoch: 19, time: 494.706s, loss: 0.127, train accuracy: 0.961\n",
            "epoch: 19, time: 496.061s, loss: 0.092, train accuracy: 0.969\n",
            "epoch: 19, time: 497.405s, loss: 0.096, train accuracy: 0.945\n",
            "epoch: 19, time: 498.762s, loss: 0.098, train accuracy: 0.969\n",
            "epoch: 19, time: 500.107s, loss: 0.089, train accuracy: 0.984\n",
            "epoch: 19, time: 501.455s, loss: 0.066, train accuracy: 0.977\n",
            "epoch: 19, time: 502.808s, loss: 0.092, train accuracy: 0.961\n",
            "epoch: 19, time: 504.151s, loss: 0.132, train accuracy: 0.961\n",
            "epoch: 20, time: 504.870s, loss: 0.141, train accuracy: 0.945\n",
            "epoch: 20, time: 506.215s, loss: 0.019, train accuracy: 0.992\n",
            "epoch: 20, time: 507.568s, loss: 0.067, train accuracy: 0.961\n",
            "epoch: 20, time: 508.911s, loss: 0.106, train accuracy: 0.977\n",
            "epoch: 20, time: 510.258s, loss: 0.107, train accuracy: 0.961\n",
            "epoch: 20, time: 511.604s, loss: 0.030, train accuracy: 1.000\n",
            "epoch: 20, time: 512.958s, loss: 0.128, train accuracy: 0.938\n",
            "epoch: 20, time: 514.301s, loss: 0.138, train accuracy: 0.953\n",
            "epoch: 20, time: 515.643s, loss: 0.030, train accuracy: 0.992\n",
            "epoch: 20, time: 516.984s, loss: 0.069, train accuracy: 0.961\n",
            "epoch: 20, time: 518.324s, loss: 0.120, train accuracy: 0.961\n",
            "epoch: 20, time: 519.657s, loss: 0.080, train accuracy: 0.961\n",
            "epoch: 20, time: 521.004s, loss: 0.055, train accuracy: 0.984\n",
            "epoch: 20, time: 522.378s, loss: 0.078, train accuracy: 0.969\n",
            "epoch: 20, time: 523.742s, loss: 0.071, train accuracy: 0.984\n",
            "epoch: 20, time: 525.094s, loss: 0.073, train accuracy: 0.961\n",
            "epoch: 20, time: 526.446s, loss: 0.176, train accuracy: 0.930\n",
            "epoch: 20, time: 527.790s, loss: 0.071, train accuracy: 0.969\n",
            "epoch: 20, time: 529.130s, loss: 0.112, train accuracy: 0.961\n",
            "epoch: 20, time: 530.478s, loss: 0.031, train accuracy: 1.000\n",
            "epoch: 21, time: 531.208s, loss: 0.068, train accuracy: 0.984\n",
            "epoch: 21, time: 532.554s, loss: 0.030, train accuracy: 0.992\n",
            "epoch: 21, time: 533.893s, loss: 0.105, train accuracy: 0.977\n",
            "epoch: 21, time: 535.235s, loss: 0.077, train accuracy: 0.977\n",
            "epoch: 21, time: 536.587s, loss: 0.031, train accuracy: 1.000\n",
            "epoch: 21, time: 537.927s, loss: 0.016, train accuracy: 0.992\n",
            "epoch: 21, time: 539.268s, loss: 0.019, train accuracy: 0.992\n",
            "epoch: 21, time: 540.613s, loss: 0.075, train accuracy: 0.977\n",
            "epoch: 21, time: 541.979s, loss: 0.102, train accuracy: 0.961\n",
            "epoch: 21, time: 543.324s, loss: 0.051, train accuracy: 0.984\n",
            "epoch: 21, time: 544.660s, loss: 0.029, train accuracy: 0.992\n",
            "epoch: 21, time: 546.010s, loss: 0.068, train accuracy: 0.984\n",
            "epoch: 21, time: 547.356s, loss: 0.073, train accuracy: 0.977\n",
            "epoch: 21, time: 548.688s, loss: 0.047, train accuracy: 0.984\n",
            "epoch: 21, time: 550.029s, loss: 0.066, train accuracy: 0.961\n",
            "epoch: 21, time: 551.372s, loss: 0.044, train accuracy: 0.992\n",
            "epoch: 21, time: 552.712s, loss: 0.111, train accuracy: 0.969\n",
            "epoch: 21, time: 554.060s, loss: 0.126, train accuracy: 0.945\n",
            "epoch: 21, time: 555.415s, loss: 0.034, train accuracy: 0.992\n",
            "epoch: 21, time: 556.762s, loss: 0.055, train accuracy: 0.977\n",
            "epoch: 22, time: 557.476s, loss: 0.076, train accuracy: 0.984\n",
            "epoch: 22, time: 558.819s, loss: 0.015, train accuracy: 1.000\n",
            "epoch: 22, time: 560.167s, loss: 0.032, train accuracy: 0.992\n",
            "epoch: 22, time: 561.510s, loss: 0.028, train accuracy: 0.992\n",
            "epoch: 22, time: 562.860s, loss: 0.123, train accuracy: 0.953\n",
            "epoch: 22, time: 564.194s, loss: 0.021, train accuracy: 0.984\n",
            "epoch: 22, time: 565.533s, loss: 0.345, train accuracy: 0.891\n",
            "epoch: 22, time: 566.882s, loss: 0.055, train accuracy: 0.977\n",
            "epoch: 22, time: 568.222s, loss: 0.011, train accuracy: 1.000\n",
            "epoch: 22, time: 569.572s, loss: 0.079, train accuracy: 0.977\n",
            "epoch: 22, time: 570.914s, loss: 0.068, train accuracy: 0.977\n",
            "epoch: 22, time: 572.259s, loss: 0.030, train accuracy: 0.992\n",
            "epoch: 22, time: 573.592s, loss: 0.028, train accuracy: 0.992\n",
            "epoch: 22, time: 574.938s, loss: 0.102, train accuracy: 0.969\n",
            "epoch: 22, time: 576.283s, loss: 0.165, train accuracy: 0.930\n",
            "epoch: 22, time: 577.621s, loss: 0.045, train accuracy: 0.984\n",
            "epoch: 22, time: 578.959s, loss: 0.079, train accuracy: 0.969\n",
            "epoch: 22, time: 580.304s, loss: 0.059, train accuracy: 0.969\n",
            "epoch: 22, time: 581.644s, loss: 0.209, train accuracy: 0.930\n",
            "epoch: 22, time: 583.018s, loss: 0.028, train accuracy: 0.992\n",
            "epoch: 23, time: 583.747s, loss: 0.028, train accuracy: 0.992\n",
            "epoch: 23, time: 585.103s, loss: 0.032, train accuracy: 0.984\n",
            "epoch: 23, time: 586.447s, loss: 0.059, train accuracy: 0.992\n",
            "epoch: 23, time: 587.800s, loss: 0.185, train accuracy: 0.945\n",
            "epoch: 23, time: 589.147s, loss: 0.036, train accuracy: 0.984\n",
            "epoch: 23, time: 590.495s, loss: 0.048, train accuracy: 0.992\n",
            "epoch: 23, time: 591.843s, loss: 0.075, train accuracy: 0.969\n",
            "epoch: 23, time: 593.188s, loss: 0.063, train accuracy: 0.984\n",
            "epoch: 23, time: 594.530s, loss: 0.128, train accuracy: 0.961\n",
            "epoch: 23, time: 595.883s, loss: 0.025, train accuracy: 1.000\n",
            "epoch: 23, time: 597.233s, loss: 0.114, train accuracy: 0.977\n",
            "epoch: 23, time: 598.573s, loss: 0.059, train accuracy: 0.984\n",
            "epoch: 23, time: 599.912s, loss: 0.060, train accuracy: 0.984\n",
            "epoch: 23, time: 601.252s, loss: 0.126, train accuracy: 0.961\n",
            "epoch: 23, time: 602.604s, loss: 0.109, train accuracy: 0.969\n",
            "epoch: 23, time: 603.955s, loss: 0.252, train accuracy: 0.930\n",
            "epoch: 23, time: 605.293s, loss: 0.031, train accuracy: 0.992\n",
            "epoch: 23, time: 606.638s, loss: 0.021, train accuracy: 1.000\n",
            "epoch: 23, time: 607.991s, loss: 0.049, train accuracy: 0.977\n",
            "epoch: 23, time: 609.335s, loss: 0.033, train accuracy: 0.992\n",
            "epoch: 24, time: 610.066s, loss: 0.142, train accuracy: 0.945\n",
            "epoch: 24, time: 611.411s, loss: 0.026, train accuracy: 0.992\n",
            "epoch: 24, time: 612.762s, loss: 0.042, train accuracy: 0.992\n",
            "epoch: 24, time: 614.116s, loss: 0.035, train accuracy: 0.977\n",
            "epoch: 24, time: 615.465s, loss: 0.064, train accuracy: 0.977\n",
            "epoch: 24, time: 616.804s, loss: 0.051, train accuracy: 0.969\n",
            "epoch: 24, time: 618.149s, loss: 0.046, train accuracy: 0.984\n",
            "epoch: 24, time: 619.491s, loss: 0.034, train accuracy: 0.984\n",
            "epoch: 24, time: 620.842s, loss: 0.053, train accuracy: 0.992\n",
            "epoch: 24, time: 622.186s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 24, time: 623.529s, loss: 0.285, train accuracy: 0.953\n",
            "epoch: 24, time: 624.882s, loss: 0.011, train accuracy: 1.000\n",
            "epoch: 24, time: 626.216s, loss: 0.101, train accuracy: 0.969\n",
            "epoch: 24, time: 627.558s, loss: 0.012, train accuracy: 1.000\n",
            "epoch: 24, time: 628.904s, loss: 0.073, train accuracy: 0.977\n",
            "epoch: 24, time: 630.247s, loss: 0.143, train accuracy: 0.969\n",
            "epoch: 24, time: 631.588s, loss: 0.020, train accuracy: 0.992\n",
            "epoch: 24, time: 632.939s, loss: 0.036, train accuracy: 0.984\n",
            "epoch: 24, time: 634.295s, loss: 0.057, train accuracy: 0.984\n",
            "epoch: 24, time: 635.667s, loss: 0.021, train accuracy: 0.984\n",
            "epoch: 25, time: 636.395s, loss: 0.107, train accuracy: 0.969\n",
            "epoch: 25, time: 637.741s, loss: 0.050, train accuracy: 0.992\n",
            "epoch: 25, time: 639.093s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 25, time: 640.441s, loss: 0.002, train accuracy: 1.000\n",
            "epoch: 25, time: 641.794s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 25, time: 643.149s, loss: 0.005, train accuracy: 1.000\n",
            "epoch: 25, time: 644.501s, loss: 0.034, train accuracy: 0.984\n",
            "epoch: 25, time: 645.857s, loss: 0.212, train accuracy: 0.945\n",
            "epoch: 25, time: 647.211s, loss: 0.030, train accuracy: 0.992\n",
            "epoch: 25, time: 648.560s, loss: 0.004, train accuracy: 1.000\n",
            "epoch: 25, time: 649.903s, loss: 0.069, train accuracy: 0.984\n",
            "epoch: 25, time: 651.264s, loss: 0.044, train accuracy: 0.977\n",
            "epoch: 25, time: 652.610s, loss: 0.019, train accuracy: 0.992\n",
            "epoch: 25, time: 653.953s, loss: 0.024, train accuracy: 1.000\n",
            "epoch: 25, time: 655.291s, loss: 0.025, train accuracy: 0.992\n",
            "epoch: 25, time: 656.650s, loss: 0.061, train accuracy: 0.977\n",
            "epoch: 25, time: 657.994s, loss: 0.041, train accuracy: 0.992\n",
            "epoch: 25, time: 659.327s, loss: 0.094, train accuracy: 0.969\n",
            "epoch: 25, time: 660.669s, loss: 0.016, train accuracy: 0.992\n",
            "epoch: 25, time: 662.019s, loss: 0.208, train accuracy: 0.930\n",
            "epoch: 26, time: 662.738s, loss: 0.029, train accuracy: 0.992\n",
            "epoch: 26, time: 664.077s, loss: 0.039, train accuracy: 0.984\n",
            "epoch: 26, time: 665.414s, loss: 0.006, train accuracy: 1.000\n",
            "epoch: 26, time: 666.765s, loss: 0.121, train accuracy: 0.977\n",
            "epoch: 26, time: 668.105s, loss: 0.052, train accuracy: 0.969\n",
            "epoch: 26, time: 669.446s, loss: 0.010, train accuracy: 1.000\n",
            "epoch: 26, time: 670.790s, loss: 0.014, train accuracy: 1.000\n",
            "epoch: 26, time: 672.125s, loss: 0.114, train accuracy: 0.969\n",
            "epoch: 26, time: 673.463s, loss: 0.114, train accuracy: 0.969\n",
            "epoch: 26, time: 674.812s, loss: 0.026, train accuracy: 1.000\n",
            "epoch: 26, time: 676.157s, loss: 0.015, train accuracy: 0.992\n",
            "epoch: 26, time: 677.509s, loss: 0.056, train accuracy: 0.977\n",
            "epoch: 26, time: 678.842s, loss: 0.018, train accuracy: 0.992\n",
            "epoch: 26, time: 680.187s, loss: 0.049, train accuracy: 0.984\n",
            "epoch: 26, time: 681.543s, loss: 0.024, train accuracy: 0.992\n",
            "epoch: 26, time: 682.890s, loss: 0.039, train accuracy: 0.992\n",
            "epoch: 26, time: 684.232s, loss: 0.051, train accuracy: 0.969\n",
            "epoch: 26, time: 685.580s, loss: 0.044, train accuracy: 0.984\n",
            "epoch: 26, time: 686.932s, loss: 0.055, train accuracy: 0.977\n",
            "epoch: 26, time: 688.298s, loss: 0.054, train accuracy: 0.992\n",
            "epoch: 27, time: 689.024s, loss: 0.015, train accuracy: 1.000\n",
            "epoch: 27, time: 690.368s, loss: 0.009, train accuracy: 1.000\n",
            "epoch: 27, time: 691.721s, loss: 0.013, train accuracy: 1.000\n",
            "epoch: 27, time: 693.069s, loss: 0.007, train accuracy: 0.992\n",
            "epoch: 27, time: 694.408s, loss: 0.012, train accuracy: 0.992\n",
            "epoch: 27, time: 695.751s, loss: 0.013, train accuracy: 1.000\n",
            "epoch: 27, time: 697.092s, loss: 0.001, train accuracy: 1.000\n",
            "epoch: 27, time: 698.449s, loss: 0.008, train accuracy: 1.000\n",
            "epoch: 27, time: 699.783s, loss: 0.035, train accuracy: 0.984\n",
            "epoch: 27, time: 701.125s, loss: 0.043, train accuracy: 0.992\n",
            "epoch: 27, time: 702.475s, loss: 0.013, train accuracy: 1.000\n",
            "epoch: 27, time: 703.824s, loss: 0.054, train accuracy: 0.984\n",
            "epoch: 27, time: 705.165s, loss: 0.118, train accuracy: 0.969\n",
            "epoch: 27, time: 706.502s, loss: 0.018, train accuracy: 0.984\n",
            "epoch: 27, time: 707.853s, loss: 0.058, train accuracy: 0.984\n",
            "epoch: 27, time: 709.202s, loss: 0.093, train accuracy: 0.969\n",
            "epoch: 27, time: 710.553s, loss: 0.016, train accuracy: 1.000\n",
            "epoch: 27, time: 711.907s, loss: 0.093, train accuracy: 0.977\n",
            "epoch: 27, time: 713.252s, loss: 0.053, train accuracy: 0.969\n",
            "epoch: 27, time: 714.595s, loss: 0.052, train accuracy: 0.984\n",
            "epoch: 28, time: 715.319s, loss: 0.071, train accuracy: 0.969\n",
            "epoch: 28, time: 716.655s, loss: 0.002, train accuracy: 1.000\n",
            "epoch: 28, time: 717.998s, loss: 0.063, train accuracy: 0.992\n",
            "epoch: 28, time: 719.334s, loss: 0.012, train accuracy: 0.992\n",
            "epoch: 28, time: 720.669s, loss: 0.002, train accuracy: 1.000\n",
            "epoch: 28, time: 722.032s, loss: 0.038, train accuracy: 0.992\n",
            "epoch: 28, time: 723.377s, loss: 0.011, train accuracy: 1.000\n",
            "epoch: 28, time: 724.709s, loss: 0.017, train accuracy: 0.992\n",
            "epoch: 28, time: 726.057s, loss: 0.014, train accuracy: 1.000\n",
            "epoch: 28, time: 727.390s, loss: 0.009, train accuracy: 1.000\n",
            "epoch: 28, time: 728.723s, loss: 0.025, train accuracy: 0.992\n",
            "epoch: 28, time: 730.064s, loss: 0.018, train accuracy: 0.992\n",
            "epoch: 28, time: 731.394s, loss: 0.078, train accuracy: 0.969\n",
            "epoch: 28, time: 732.735s, loss: 0.018, train accuracy: 0.992\n",
            "epoch: 28, time: 734.078s, loss: 0.004, train accuracy: 1.000\n",
            "epoch: 28, time: 735.415s, loss: 0.008, train accuracy: 1.000\n",
            "epoch: 28, time: 736.753s, loss: 0.040, train accuracy: 0.984\n",
            "epoch: 28, time: 738.097s, loss: 0.318, train accuracy: 0.961\n",
            "epoch: 28, time: 739.440s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 28, time: 740.798s, loss: 0.012, train accuracy: 1.000\n",
            "epoch: 29, time: 741.516s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 29, time: 742.864s, loss: 0.011, train accuracy: 0.992\n",
            "epoch: 29, time: 744.204s, loss: 0.050, train accuracy: 0.984\n",
            "epoch: 29, time: 745.543s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 29, time: 746.895s, loss: 0.005, train accuracy: 1.000\n",
            "epoch: 29, time: 748.260s, loss: 0.001, train accuracy: 1.000\n",
            "epoch: 29, time: 749.615s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 29, time: 750.969s, loss: 0.007, train accuracy: 1.000\n",
            "epoch: 29, time: 752.316s, loss: 0.025, train accuracy: 0.984\n",
            "epoch: 29, time: 753.661s, loss: 0.001, train accuracy: 1.000\n",
            "epoch: 29, time: 755.006s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 29, time: 756.348s, loss: 0.014, train accuracy: 1.000\n",
            "epoch: 29, time: 757.691s, loss: 0.008, train accuracy: 1.000\n",
            "epoch: 29, time: 759.035s, loss: 0.003, train accuracy: 1.000\n",
            "epoch: 29, time: 760.383s, loss: 0.024, train accuracy: 0.992\n",
            "epoch: 29, time: 761.740s, loss: 0.067, train accuracy: 0.992\n",
            "epoch: 29, time: 763.099s, loss: 0.015, train accuracy: 1.000\n",
            "epoch: 29, time: 764.459s, loss: 0.014, train accuracy: 0.992\n",
            "epoch: 29, time: 765.810s, loss: 0.043, train accuracy: 0.984\n",
            "epoch: 29, time: 767.174s, loss: 0.023, train accuracy: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uc1816EHVQY",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hItOOXuwCD0w",
        "colab_type": "code",
        "outputId": "c4400479-cf31-42ac-ec6e-52aabe65d1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct_total = 0\n",
        "\n",
        "for i, (x_batch, y_batch) in enumerate(testloader):\n",
        "  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n",
        "\n",
        "  y_pred = net(x_batch)\n",
        "  y_pred_max = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n",
        "\n",
        "print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the test set: 0.792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woDv4gpdY85_",
        "colab_type": "text"
      },
      "source": [
        "### Define a function to show an input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h5iFcBkC3ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "inverse_transform = transforms.Compose([transforms.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), \n",
        "                                        transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]),\n",
        "                               ])\n",
        "\n",
        "# Function to show an image tensor\n",
        "def show(X):\n",
        "    X = invTrans(X)\n",
        "\n",
        "    plt.imshow(np.transpose(X.numpy(), (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61nCgln8HZaN",
        "colab_type": "text"
      },
      "source": [
        "### Show the model's prediction for a random sample from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2grnY_u2-O2",
        "colab_type": "code",
        "outputId": "ae55b590-b90a-4fea-d241-96350e72bfcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "# choose a picture at random\n",
        "im_minibatch, label_minibatch = iter(testloader).next()\n",
        "im, label = im_minibatch[0].cpu(), label_minibatch[0].cpu()\n",
        "\n",
        "# diplay the picture\n",
        "show(im)\n",
        "\n",
        "# feed it to the net and display the confidence scores\n",
        "prob = F.softmax(net.cpu()(im.unsqueeze(0)), dim=1)\n",
        "\n",
        "print('Confidence scores:\\n' + '\\n'.join(['{}: {}'.format(classes[i], p.item()) for i, p in enumerate(prob.squeeze())]))\n",
        "\n",
        "print('\\nLabel with highest confidence score: {}'.format(classes[torch.argmax(prob).item()]))\n",
        "print('\\nTrue label: {}'.format(classes[label]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Confidence scores:\n",
            "plane: 1.0\n",
            "car: 2.1552328689846496e-22\n",
            "bird: 5.393927492158834e-12\n",
            "cat: 2.1109357005986464e-15\n",
            "deer: 7.042923504625484e-21\n",
            "dog: 1.3179952265231403e-22\n",
            "frog: 1.1797641272214466e-21\n",
            "horse: 8.030302506201037e-21\n",
            "ship: 9.343617132439737e-19\n",
            "truck: 2.1920653778728194e-21\n",
            "\n",
            "Label with highest confidence score: plane\n",
            "\n",
            "True label: plane\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XsdKToFor69U"},"source":["# Homework 3, exercise 2 - Residual Neural Network on CIFAR10\n","\n","In this exercise we implement a (slightly modified) ResNet as introduced in [this paper](https://arxiv.org/pdf/1512.03385.pdf)."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"1VdY58D3KMZO"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import time"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sRuR6CcbsW8_"},"source":["For this exercise it is recommended to use the GPU!"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":978,"status":"ok","timestamp":1576003485265,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"},"user_tz":-60},"id":"rhZQhrlxKSTK","outputId":"080851ee-4233-4e39-e5ab-ecde4d88530a"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\n","use_cuda = True\n","\n","if use_cuda and torch.cuda.is_available():\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","\n","device"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pwJz3i37UXsZ"},"source":["### Load the CIFAR10 dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":2310,"status":"ok","timestamp":1576005182727,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"},"user_tz":-60},"id":"e1WVamZiKSXR","outputId":"3ad28be0-c0d3-48f8-de13-5bbdc49dd617"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data_cifar', train=True,\n","                                        download=True, transform=transform_train)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False,\n","                                       download=True, transform=transform_test)\n","\n","batch_size = 128\n","\n","c, w, h = 3, 32, 32\n","\n","trainloader = torch.utils.data.DataLoader(trainset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)\n","\n","testloader = torch.utils.data.DataLoader(testset,\n","                                         batch_size=batch_size,\n","                                         shuffle=True)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hfpdVQRbUg5p"},"source":["## Exercise - Implement a Residual Block\n","\n","Residual neural networks mainly consist of components called Residual Blocks. One residual block can be expressed as **y** = *F*(**x**) + **x** where **x** and **y** are the input and output of the block, respectively. So the input **x** is added to the result of *F*(**x**) using a *skip connection*. In this exercise, *F* consists of:\n","* a convolutional layer with `in_channels` input channels, `hidden_channels` output channels, a kernel size of (3, 3), a stride of 1, padding of 1 and no bias parameter.\n","* a batch normalisation layer \n","* ReLU activation\n","* a convolutional layer with `hidden_channels` input channels, `out_channels` output channels, a kernel size of (3, 3), a stride of 1, padding of 1 and no bias parameter.\n","* a batch normalisation layer\n","\n","After this the `skip_connection` is applied. If the dimensions of *F*(**x**) and **x** don't match an extra linear projection is applied to **x** so the dimensions do match. This has already been implemented for you. You only need to call it at the right place. \n","Finally, a ReLU activation is applied on the output **y**\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","id":"HK1qpjYwUFqh"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResidualBlock(\n","  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (skip_connection): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")\n"]}],"source":["class ResidualBlock(nn.Module):\n","\n","  def __init__(self, in_channels, hidden_channels, out_channels):\n","    super(ResidualBlock, self).__init__()\n","    # Complete the code here\n","\n","    # Define the layers fpr the residual block\n","    self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","    self.bn1 = nn.BatchNorm2d(hidden_channels)\n","    self.conv2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","    self.bn2 = nn.BatchNorm2d(out_channels)\n","        \n","    # Define the skip connection\n","    if in_channels != out_channels:  # F(x) and x dimensions do not match! Define a projection for input x\n","      self.skip_connection = nn.Sequential(\n","          nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n","          nn.BatchNorm2d(out_channels)\n","      )\n","    else:\n","      self.skip_connection = lambda x: x  # The dimensions already match! No need to do a projection on x\n","\n","  def forward(self, x):\n","    #pass  # Complete the code here!\n","    identity = self.skip_connection(x)\n","    out = F.relu(self.bn1(self.conv1(x)))\n","    out = self.bn2(self.conv2(out))\n","\n","    out += identity\n","    out = F.relu(out)\n","\n","    return out\n","\n","\n","# Example usage\n","# Define a residual block with 64 input channels, 128 hidden channels, and 128 output channels\n","residual_block = ResidualBlock(in_channels=64, hidden_channels=128, out_channels=128)\n","print(residual_block)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T1Y87D77cYX8"},"source":["## Exercise - Implement a Residual Neural Network\n","Now you can use the previously defined Residual Block to create your ResNet.\n","\n","The network consists of:\n","* a convolutional layer with `in_channels` input channels, 64 output channels, a stride of 1, padding of 1 and no bias parameter,\n","* a batch normalisation layer\n","* ReLU activation\n","* a max pooling layer with kernel size (3, 3), a stride of 2 and padding of 1,\n","* eight residual blocks, with (64, 64, 128, 128, 256, 256, 512, 512) channels, respectively (see code below) \n","* an average pooling layer over all feature maps (already present)\n","* a dense layer to form the output distribution (already present)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","id":"0qVgN9lPKSeC"},"outputs":[],"source":["class ResNet(nn.Module):\n","\n","  def __init__(self, in_channels, out_size):\n","    super().__init__()\n","\n","    # Complete the code here!\n","\n","\n","    self.res_blocks = nn.ModuleList(\n","        [\n","         ResidualBlock(64, 64, 64),\n","         ResidualBlock(64, 64, 64),\n","         \n","         ResidualBlock(64, 128, 128),\n","         ResidualBlock(128, 128, 128),\n","         \n","         ResidualBlock(128, 256, 256),\n","         ResidualBlock(256, 256, 256),\n","\n","         ResidualBlock(256, 512, 512),\n","         ResidualBlock(512, 512, 512),\n","        ]\n","    )\n","\n","    self.dense_layer = nn.Linear(512, out_size)\n","    \n","    for module in self.modules():\n","      if isinstance(module, nn.Conv2d):\n","          nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n","\n","  def forward(self, x):  \n","\n","    # Complete the code here!\n","    # Add everything that needs to be done before the average pooling\n","\n","\n","    x = F.avg_pool2d(x, x.shape[2:])\n","    \n","    x = x.view(x.size(0), -1)\n","    x = self.dense_layer(x)\n","\n","    return x\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DZ9ny4USgNAu"},"source":["### Initialize the network, Loss function and Optimizer"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","id":"FIofWmkrT6Oh"},"outputs":[],"source":["net = ResNet(c, len(classes)).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ojw0pS0dgZHX"},"source":["## Exercise - Train/evaluate the network\n","Train the network you built using the code below. Add the following answers in your report:\n","* What test accuracy were you able to get?\n","* How many layers does your network have? (counting only convolutional and dense layers)\n","* Why do the skip connections help for training deep neural networks?"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","id":"IcG_bfjoT7Dx","outputId":"a5280aa9-5f1c-4867-b0e8-8444b5795ee5"},"outputs":[{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (128x3 and 512x10)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move the data to the device that is used\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Set all currenly stored gradients to zero \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_batch)\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 40\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mavg_pool2d(x, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x3 and 512x10)"]}],"source":["start=time.time()\n","\n","for epoch in range(0,200):\n","\n","  net.train()  # Put the network in train mode\n","  for i, (x_batch, y_batch) in enumerate(trainloader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","    \n","    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n","\n","    y_pred = net(x_batch)\n","\n","    loss = criterion(y_pred, y_batch)\n","\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    # Compute relevant metrics\n","    \n","    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n","\n","    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n","\n","    elapsed = time.time() - start  # Keep track of how much time has elapsed\n","\n","    # Show progress every 20 batches \n","    if not i % 20:\n","      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n","    \n","    correct_total = 0\n","\n","  net.eval()  # Put the network in eval mode\n","  for i, (x_batch, y_batch) in enumerate(testloader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","\n","    y_pred = net(x_batch)\n","    y_pred_max = torch.argmax(y_pred, dim=1)\n","\n","    correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n","\n","  print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"0jcJkRe8T7BW"},"outputs":[],"source":["correct_total = 0\n","\n","for i, (x_batch, y_batch) in enumerate(testloader):\n","  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","\n","  y_pred = net(x_batch)\n","  y_pred_max = torch.argmax(y_pred, dim=1)\n","\n","  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n","\n","print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"V4RSHW_QT6Ls"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"rmaaXUzTT6Ix"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"0cbLSRfqT6F3"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"resnet_on_cifar10.ipynb","provenance":[{"file_id":"1AswAne0soFX43THh56ZlZa7VQfgRLIGo","timestamp":1576010367797}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPU Tutorial.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OL5Pt0sgKcKP","colab_type":"text"},"source":["# PyTorch - How to use the GPU\n","Most of the computations that are done when training your deep learning model will consist of matrix multiplications. GPUs are optimized for these type of computations and can therefore greatly decrease the time it takes to train your model. When your models become larger, this can save hours or even days of training. This lab explains how to use the GPU in PyTorch. "]},{"cell_type":"markdown","metadata":{"id":"MHLYobqxNVit","colab_type":"text"},"source":["We recommend you use the GPU provided by Colab instead of the one in your laptop, as these are much better and also simplify the tool installation. Also, PyTorch makes use of CUDA, which is a platform for general purpose computing on GPUs. Not all GPUs are compatible with CUDA. "]},{"cell_type":"markdown","metadata":{"id":"82PYF9HWRqx-","colab_type":"text"},"source":["PyTorch tensors are either allocated on the CPU or GPU. Tensors located on the CPU cannot interact with those on the GPU and vice versa. This is something you need to keep track of when programming your models. "]},{"cell_type":"code","metadata":{"id":"lFh55qa4Rjfs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nz_GpnBNIsvG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uy0bptrIvQu","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnnUrjaEIvTe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ca9cca46-14c0-4a7d-c627-1e804d1565e7","executionInfo":{"status":"ok","timestamp":1573202810034,"user_tz":-60,"elapsed":1227,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"}}},"source":["if torch.cuda.is_available():\n","  print('GPU is available!')\n","  device = torch.device('cuda')\n","else:\n","  print('GPU is not available!')\n","  device = torch.device('cpu')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["GPU is available!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cL_N6UEYIx7q","colab_type":"code","colab":{}},"source":["tensor_1 = torch.randn(4, device=torch.device('cpu'))   # CPU tensor\n","tensor_2 = torch.randn(4, device=torch.device('cuda'))  # GPU tensor\n","tensor_3 = torch.randn(4, device=device)\n","tensor_4 = torch.randn(4)  # By default, tensors are initialized as CPU tensors"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEX2WklWIx5C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"bef29643-d9e3-4d38-acd8-245afd58b9fb","executionInfo":{"status":"error","timestamp":1573202821948,"user_tz":-60,"elapsed":955,"user":{"displayName":"Ron van Bree","photoUrl":"","userId":"10574495138637938052"}}},"source":["tensor_1 * tensor_2"],"execution_count":4,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-41afa0745a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtensor_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: expected device cpu but got device cuda:0"]}]},{"cell_type":"markdown","metadata":{"id":"BQABtpIuGiXt","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"EG0EJ6PWIvOU","colab_type":"code","colab":{}},"source":["tensor_3 * tensor_4.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcT6OvS7H7Jc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y538VmgqH7PP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4zHiewpH7Mt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}